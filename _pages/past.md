<h2 class="col">
<font color=blue>Industrial Experiences</font>
</h2>

<!-- 0 -->
<div class="section-text col-right">
<h3><a href="#" style="text-decoration: none;"><span class="emph">Develop ColossalAI Inference Engine for LLM</span></a></h3>
</div>

<div><a href="https://hpc-ai.com/" style="text-decoration: none;">@HPCAI-Tech Company</a>
<font size ="2"> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; Beijing, China; March 2024 - July 2024</font>
</div>

* Project: [ColossalAI](https://github.com/hpcaitech/ColossalAI), an open source project with **37k+** stars in Github
<!-- * Role: Core Developer of Inference Team -->
* Mentor: [Yuanheng Zhao](https://github.com/yuanheng-zhao), [Shenggui Li](https://franklee.xyz/) and [Hongxin Liu](https://github.com/ver217)
<!-- * Duties included: Core InferenceEngine Developer, some examples I built: -->
  <!-- * [[feat]CUDA Graph Support](https://github.com/hpcaitech/ColossalAI/pull/5434): CUDA Graph Support and Refactor non-functional api -->
  <!-- * [[feat]Tensor Model Parallel Support For Inference](https://github.com/hpcaitech/ColossalAI/pull/5563): Tensor Model Parallel Support For Inference -->
  <!-- * [[feat]Inference RPC Server Support](https://github.com/hpcaitech/ColossalAI/pull/5705): RPC Support for Online Serving  -->

<!-- 1 -->
<div class="section-text col-right">
<h3><a href="#" style="text-decoration: none;"><span class="emph">Optimize the LLVM Backend of SenseTime GPU, GPU Compiler</span></a></h3>
</div>

<div><a href="https://www.sensetime.com/en" style="text-decoration: none;">@Sensetime Company</a>
<font size ="2"> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; Shanghai, China; April 2023 - Augu 2023</font>
</div>

* Project: LLVM, the internal version of SenseTime
<!-- * Role: LLVMer -->
* Mentor: Wenqiang Yin
<!-- * Duties included: Optimizing the backend of LLVM based on the SenseTime GPU. -->
  <!-- * 4000+ line LLVM GPU Backend Optimization Codes -->
  <!-- * Instruction Selection, Instruction Pattern Match, such as optimize the ld/st into async_ld/st, CodeGen Emitter -->
  <!-- * Optimize the threadidx/blockDim based on their range. -->
  <!-- * If there's one thing LLVM has taught me, it's that patience is a virtue. A virtue I never knew I had until I spent countless hours debugging its intricacies :(  -->

<div class="section-text col-right">
<h3><a href="#" style="text-decoration: none;"><span class="emph">Develop High</span> Performance Neural Network Inference Engine</a></h3>
</div>

<!-- 2 -->
<div><a href="https://www.tencent.com/en-us/" style="text-decoration: none;">@Tencent Company</a>
<font size ="2"> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;&nbsp;&emsp; &emsp;&emsp;&nbsp;&emsp; &emsp;&emsp;ShenZhen, China; June 2022 - Nov. 2022 </font>
</div>

* Project: [ncnn](https://github.com/Tencent/ncnn), an open source project with **18k+** stars in Github
<!-- * Role: Top15 committer(util `Nov.2022`) of 269 committers in total -->
* Mentor: [nihui](https://github.com/nihui)(*with Github **6k** followers*), and she's cute :)
<!-- * Duties included: Write and Optimize(such as SIMD) operators for ncnn, mainly aligned with pytorch, some examples I built: -->
  <!-- * [GridSample](https://github.com/Tencent/ncnn/pull/4288): Given an input and a flow-field grid, computes the output using input values and pixel locations from grid. -->
  <!-- * To be noted, the PNNX of ncnn, a new `PyTorch Neural Network eXchange`, draw on the design concept of `MLIR`-->    
  <!-- * [GELU](https://github.com/Tencent/ncnn/pull/4144): Implement `sse/avx/avx512` version of gelu, with a fast version of `erfc`.  -->

<!-- 3 -->
<!-- <div class="section-text col-right"> -->
<!-- <h3><a href="#" style="text-decoration: none;"><span class="emph">Deploy</span> High-FPS AI Models on Arm Chips</a></h3> -->
<!-- </div> -->
<!--  -->
<!-- <div><a href="https://en.fiberhome.com/" style="text-decoration: none;"> @FiberHome Telecommunication Company</a> -->
<!-- <font size ="2"> &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; WuHan, China; April 2021 - June.2021</font> -->
<!-- </div> -->
<!--  -->
<!-- > Establish a team of 7 undergraduate, 1 postgraduate in total for This Project. -->
<!--  -->
<!-- * Role: **Leader** @ [Dian.AI](https://dian.org.cn/) -->
<!-- * Mentor: [Yayu Gao](https://scholar.google.com.hk/citations?user=o42amRcAAAAJ) -->
<!-- * Mentor of AI Group: [Xinggang Wang](https://scholar.google.com/citations?user=qNCTLV0AAAAJ&hl=en) -->
<!-- * Duties included: As the project leader  -->
  <!-- - Arm CPU/20FPS/ Snapdragon 870 -->
  <!-- - YOLOX/Lite-HRNet -->
  <!-- - pattern match algorithm/Hungarian Algorithm -->

<!-- 2
<div class="section-text col-right">
<h3><a href="#" style="text-decoration: none;"><span class="emph">Explore</span> Backdoor Attack on Transformer Models</a></h3>
</div>

<div><a href="https://mathcenter.hust.edu.cn/Research_Groups/John_Hopcroft_Lab_for_Data_Science.htm" style="text-decoration: none;">John Hopcroft Lab for Data Science</a>
<font size ="2"> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; WuHan, China; April. 2022 - Augu.2023 </font>
</div>

* Role: Research Intern
* Mentor: [Kun He](https://scholar.google.com/citations?user=YTQnGJsAAAAJ&hl=en)
* Duties included:  Research the model security of classic classification models such as ViT and DeiT, with a focus on black-box attacks. -->

<!-- <h2 class="col">
<font color=blue>Honors</font>
</h2>

* Tencent Scholarship (2023)
* Huawei "Intelligent Base" Scholarship (2022)

* Science and Technology Innovation Scholarship(2022), School of Computer Science and Technology, HUST
* Academic Excellence Scholarship(2021), School of Computer Science and Technology, HUST
* Academic Excellence Scholarship(2020), School of Computer Science and Technology, HUST -->

<!-- ### to be completed  -->

